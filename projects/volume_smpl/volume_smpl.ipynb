{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/xuchen/fast-snarf/lib/model/smpl.py:30: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.betas = torch.tensor(betas).float().cuda()\n",
      "/tmp/ipykernel_1488962/710704671.py:83: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  opt = Munch(yaml.load(open('config/deformer/fast_snarf.yaml'))['model']['deformer']['opt'])\n",
      "  5%|▍         | 46/1000 [00:00<00:02, 451.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104.52366638183594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 173/1000 [00:00<00:02, 379.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104.15771484375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 252/1000 [00:00<00:01, 386.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104.99578094482422\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 372/1000 [00:00<00:01, 392.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104.59601593017578\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 452/1000 [00:01<00:01, 394.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104.04641723632812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 572/1000 [00:01<00:01, 391.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102.867919921875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 652/1000 [00:01<00:00, 391.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103.86639404296875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 772/1000 [00:01<00:00, 390.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103.95658111572266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 853/1000 [00:02<00:00, 394.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103.87657928466797\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 974/1000 [00:02<00:00, 394.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104.16500091552734\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:02<00:00, 391.32it/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "os.chdir('/local/home/xuchen/fast-snarf')\n",
    "import torch\n",
    "from tqdm import trange, tqdm\n",
    "import yaml\n",
    "from munch import Munch\n",
    "from lib.utils.check_sign import check_sign\n",
    "from lib.model.smpl import SMPLServer\n",
    "from lib.model.network_ngp import ImplicitNetwork\n",
    "from lib.model.fast_snarf import ForwardDeformer\n",
    "from lib.model.helpers import masked_softmax\n",
    "from lib.utils.meshing import generate_mesh\n",
    "from lib.model.sample import PointInSpace\n",
    "from pytorch3d.io.obj_io import load_obj,load_objs_as_meshes\n",
    "import trimesh\n",
    "from pysdf import SDF\n",
    "import pandas\n",
    "from pytorch3d.ops import sample_points_from_meshes\n",
    "\n",
    "with_texture = True\n",
    "def occ_func(x):\n",
    "    batch_points = 200000000\n",
    "    acc = []\n",
    "    for pts_d_split in torch.split(x, batch_points, dim=1):\n",
    "        \n",
    "        pts_d_split = (pts_d_split + deformer.offset) * deformer.scale\n",
    "        pts_d_split = (pts_d_split+1)/2\n",
    "        \n",
    "        occ = network(pts_d_split, {'smpl': smpl_params[:,7:-10]/np.pi})[...,:1]\n",
    "    \n",
    "        mask = torch.logical_or(pts_d_split.max(-1).values >= 1, pts_d_split.min(-1).values <= 0)\n",
    "        occ[mask] = -100\n",
    "\n",
    "        acc.append(occ)\n",
    "    acc = torch.cat(acc,dim=1).reshape(-1, 1)\n",
    "    return acc\n",
    "\n",
    "def prepare_data(scan_verts, scan_faces):\n",
    "\n",
    "    _, num_verts, num_dim = scan_verts.shape\n",
    "    random_idx = torch.randint(0, num_verts, [1, int(1e8), 1], device=scan_verts.device)\n",
    "    random_pts = torch.gather(scan_verts, 1, random_idx.expand(-1, -1, num_dim)).float()\n",
    "    pts_d = sampler.get_points(random_pts)\n",
    "\n",
    "\n",
    "    mesh = trimesh.Trimesh(vertices=scan_verts[0].cpu().numpy(), faces=scan_faces.cpu().numpy())\n",
    "    sdf_obj = SDF(mesh.vertices, mesh.faces)\n",
    "    sdf_gt = sdf_obj(pts_d[0].cpu().numpy())\n",
    "    sdf_gt = torch.tensor(sdf_gt).cuda().float().unsqueeze(0)\n",
    "    # sdf_gt = sdf_gt.clamp(-1,1)\n",
    "    return sdf_gt, pts_d\n",
    "\n",
    "\n",
    "# Prepare the data\n",
    "\n",
    "\n",
    "smpl_params = torch.zeros(86).cuda().float()[None]\n",
    "smpl_params[0,0] = 1\n",
    "\n",
    "gender      = 'male'\n",
    "betas       = smpl_params[:,-10:]\n",
    "smpl_server = SMPLServer(gender=gender, betas=betas).cuda()\n",
    "sampler = PointInSpace(global_sigma=1.8, local_sigma=0.01)\n",
    "\n",
    "\n",
    "smpl_outputs = smpl_server.forward(smpl_params)\n",
    "smpl_verts = smpl_outputs['smpl_verts']\n",
    "smpl_verts_cano = smpl_server.verts_c\n",
    "smpl_faces = torch.tensor(smpl_server.smpl.faces.astype('int')).cuda()\n",
    "num_dim = 3\n",
    "\n",
    "\n",
    "smpl_tfs = smpl_outputs['smpl_tfs']\n",
    "cond = {'smpl': smpl_params[:,7:-10].cuda()/np.pi, 'smpl_params': smpl_params.cuda()}\n",
    "\n",
    "sdf_gt_smpl, pts_d_smpl = prepare_data(smpl_verts_cano, smpl_faces)\n",
    "\n",
    "# Canonical model\n",
    "network = ImplicitNetwork(3, 1, 64, 3).cuda()\n",
    "\n",
    "# Deformer\n",
    "opt = Munch(yaml.load(open('config/deformer/fast_snarf.yaml'))['model']['deformer']['opt'])\n",
    "opt.skinning_mode = 'preset'\n",
    "opt.cvg = float(opt.cvg)\n",
    "opt.dvg = float(opt.dvg)\n",
    "deformer = ForwardDeformer(opt,smpl_server).cuda()\n",
    "\n",
    "# Optimizer\n",
    "optimizer = torch.optim.Adam(network.parameters(), lr=1e-3)\n",
    "\n",
    "for iter in trange(1000):\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    random_idx = torch.randint(0, pts_d_smpl.shape[1], [1, int(1e5), 1], device=pts_d_smpl.device)\n",
    "    pts_c = torch.gather(pts_d_smpl, 1, random_idx.expand(-1, -1, num_dim)).float()\n",
    "    sdf_gt_cur = torch.gather(sdf_gt_smpl, 1, random_idx.squeeze(-1)).float()\n",
    "\n",
    "    pts_c = ((pts_c + deformer.offset) * deformer.scale+1)/2\n",
    "    occ_pd = network(pts_c, cond)[:,:,:1]\n",
    "\n",
    "    loss = torch.nn.functional.l1_loss(occ_pd, sdf_gt_cur.unsqueeze(-1))\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if iter%100==0:\n",
    "        print(loss.item())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1488962/3137189700.py:29: FutureWarning: marching_cubes_lewiner is deprecated in favor of marching_cubes. marching_cubes_lewiner will be removed in version 0.19\n",
      "  verts, faces, normals, values = measure.marching_cubes_lewiner(\n",
      "face_normals incorrect shape, ignoring!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.273414611816406\n",
      "18.13340187072754\n"
     ]
    }
   ],
   "source": [
    "from lib.model.helpers import create_voxel_grid\n",
    "import time\n",
    "import numpy as np\n",
    "import torch\n",
    "from skimage import measure\n",
    "from lib.libmise import mise\n",
    "import trimesh\n",
    "\n",
    "res = 64\n",
    "start = time.time()\n",
    "grid = create_voxel_grid(res,res,res,device='cuda')\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "pts_c, intermediates = deformer(grid, cond, smpl_tfs, eval_mode=True)\n",
    "mask = intermediates['valid_ids']\n",
    "\n",
    "num_batch, num_point, num_init, num_dim = pts_c.shape\n",
    "pts_c = pts_c.reshape(num_batch, num_point * num_init, num_dim)\n",
    "\n",
    "pts_c = ((pts_c + deformer.offset) * deformer.scale+1)/2\n",
    "occ_pd = network(pts_c, cond, mask=mask.reshape(num_batch*num_point * num_init))[:,:,:1].reshape(num_batch, num_point, num_init)\n",
    "occ_pd = masked_softmax(occ_pd, mask, dim=-1, mode='max', soft_blend=5)\n",
    "print((time.time()-start)*1000)\n",
    "\n",
    "value_grid = occ_pd.reshape(res,res,res).data.cpu().numpy()\n",
    "\n",
    "start = time.time()\n",
    "verts, faces, normals, values = measure.marching_cubes_lewiner(\n",
    "                                            volume=value_grid,\n",
    "                                            gradient_direction='ascent',\n",
    "                                            level=min(0, value_grid.max()))\n",
    "\n",
    "# verts = (verts / mesh_extractor.resolution - 0.5) * scale\n",
    "# verts = verts * gt_scale + gt_center\n",
    "meshexport = trimesh.Trimesh(verts, faces, normals, vertex_colors=values)\n",
    "meshexport.export('test.obj')\n",
    "print((time.time()-start)*1000)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import taichi as ti\n",
    "\n",
    "ti.init(arch=ti.gpu)\n",
    "res = 1280, 720\n",
    "color_buffer = ti.Vector.field(3, dtype=ti.f32, shape=res)\n",
    "sdf_field = ti.field(dtype=ti.f32, shape=(128,128,128))\n",
    "max_ray_depth = 6\n",
    "eps = 1e-4\n",
    "inf = 1e10\n",
    "\n",
    "fov = 0.23\n",
    "dist_limit = 100\n",
    "\n",
    "camera_pos = ti.Vector([0.0, 0.32, 3.7])\n",
    "light_pos = [-1.5, 0.6, 0.3]\n",
    "light_normal = [1.0, 0.0, 0.0]\n",
    "light_radius = 2.0\n",
    "\n",
    "\n",
    "@ti.func\n",
    "def intersect_light(pos, d):\n",
    "    light_loc = ti.Vector(light_pos)\n",
    "    dot = -d.dot(ti.Vector(light_normal))\n",
    "    dist = d.dot(light_loc - pos)\n",
    "    dist_to_light = inf\n",
    "    if dot > 0 and dist > 0:\n",
    "        D = dist / dot\n",
    "        dist_to_center = (light_loc - (pos + D * d)).norm_sqr()\n",
    "        if dist_to_center < light_radius**2:\n",
    "            dist_to_light = D\n",
    "    return dist_to_light\n",
    "\n",
    "\n",
    "@ti.func\n",
    "def out_dir(n):\n",
    "    u = ti.Vector([1.0, 0.0, 0.0])\n",
    "    if abs(n[1]) < 1 - eps:\n",
    "        u = n.cross(ti.Vector([0.0, 1.0, 0.0])).normalized()\n",
    "    v = n.cross(u)\n",
    "    phi = 2 * math.pi * ti.random()\n",
    "    ay = ti.sqrt(ti.random())\n",
    "    ax = ti.sqrt(1 - ay**2)\n",
    "    return ax * (ti.cos(phi) * u + ti.sin(phi) * v) + ay * n\n",
    "\n",
    "\n",
    "@ti.func\n",
    "def make_nested(f):\n",
    "    f = f * 40\n",
    "    i = int(f)\n",
    "    if f < 0:\n",
    "        if i % 2 == 1:\n",
    "            f -= ti.floor(f)\n",
    "        else:\n",
    "            f = ti.floor(f) + 1 - f\n",
    "    f = (f - 0.2) / 40\n",
    "    return f\n",
    "\n",
    "\n",
    "# https://www.iquilezles.org/www/articles/distfunctions/distfunctions.htm\n",
    "@ti.func\n",
    "def sdf(o):\n",
    "    wall = ti.min(o[1] + 0.1, o[2] + 0.4)\n",
    "\n",
    "    if ti.min(o) >= 0 and ti.max(o) < 1:\n",
    "        return ti.min(wall, sdf_field[ti.cast(o*128,ti.int32)])\n",
    "    \n",
    "    # wall = ti.min(o[1] + 0.1, o[2] + 0.4)\n",
    "    # sphere = (o - ti.Vector([0.0, 0.35, 0.0])).norm() - 0.36\n",
    "\n",
    "    # q = ti.abs(o - ti.Vector([0.8, 0.3, 0])) - ti.Vector([0.3, 0.3, 0.3])\n",
    "    # box = ti.Vector([ti.max(0, q[0]),\n",
    "    #                  ti.max(0, q[1]),\n",
    "    #                  ti.max(0, q[2])]).norm() + ti.min(q.max(), 0)\n",
    "\n",
    "    # O = o - ti.Vector([-0.8, 0.3, 0])\n",
    "    # d = ti.Vector([ti.Vector([O[0], O[2]]).norm() - 0.3, abs(O[1]) - 0.3])\n",
    "    # cylinder = ti.min(d.max(), 0.0) + ti.Vector(\n",
    "    #     [ti.max(0, d[0]), ti.max(0, d[1])]).norm()\n",
    "\n",
    "    # geometry = make_nested(ti.min(sphere, box, cylinder))\n",
    "    # geometry = ti.max(geometry, -(0.32 - (o[1] * 0.6 + o[2] * 0.8)))\n",
    "    return wall #ti.min(wall, geometry)\n",
    "\n",
    "\n",
    "@ti.func\n",
    "def ray_march(p, d):\n",
    "    j = 0\n",
    "    dist = 0.0\n",
    "    while j < 100 and sdf(p + dist * d) > 1e-6 and dist < inf:\n",
    "        dist += sdf(p + dist * d)\n",
    "        j += 1\n",
    "    return ti.min(inf, dist)\n",
    "\n",
    "\n",
    "@ti.func\n",
    "def sdf_normal(p):\n",
    "    d = 1e-3\n",
    "    n = ti.Vector([0.0, 0.0, 0.0])\n",
    "    sdf_center = sdf(p)\n",
    "    for i in ti.static(range(3)):\n",
    "        inc = p\n",
    "        inc[i] += d\n",
    "        n[i] = (1 / d) * (sdf(inc) - sdf_center)\n",
    "    return n.normalized()\n",
    "\n",
    "\n",
    "@ti.func\n",
    "def next_hit(pos, d):\n",
    "    closest, normal, c = inf, ti.Vector.zero(ti.f32,\n",
    "                                             3), ti.Vector.zero(ti.f32, 3)\n",
    "    ray_march_dist = ray_march(pos, d)\n",
    "    if ray_march_dist < dist_limit and ray_march_dist < closest:\n",
    "        closest = ray_march_dist\n",
    "        normal = sdf_normal(pos + d * closest)\n",
    "        hit_pos = pos + d * closest\n",
    "        t = int((hit_pos[0] + 10) * 1.1 + 0.5) % 3\n",
    "        c = ti.Vector(\n",
    "            [0.4 + 0.3 * (t == 0), 0.4 + 0.2 * (t == 1), 0.4 + 0.3 * (t == 2)])\n",
    "    return closest, normal, c\n",
    "\n",
    "\n",
    "@ti.kernel\n",
    "def fill_sdf():\n",
    "    for x,y,z in sdf_field:\n",
    "        o = ti.Vector([x,y,z])/128.\n",
    "        sphere = (o - ti.Vector([0.0, 0.35, 0.0])).norm() - 0.36\n",
    "\n",
    "        q = ti.abs(o - ti.Vector([0.8, 0.3, 0])) - ti.Vector([0.3, 0.3, 0.3])\n",
    "        box = ti.Vector([ti.max(0, q[0]),\n",
    "                         ti.max(0, q[1]),\n",
    "                         ti.max(0, q[2])]).norm() + ti.min(q.max(), 0)\n",
    "\n",
    "        O = o - ti.Vector([-0.8, 0.3, 0])\n",
    "        d = ti.Vector([ti.Vector([O[0], O[2]]).norm() - 0.3, abs(O[1]) - 0.3])\n",
    "        cylinder = ti.min(d.max(), 0.0) + ti.Vector(\n",
    "            [ti.max(0, d[0]), ti.max(0, d[1])]).norm()\n",
    "\n",
    "        geometry = make_nested(ti.min(sphere, box, cylinder))\n",
    "        geometry = ti.max(geometry, -(0.32 - (o[1] * 0.6 + o[2] * 0.8)))\n",
    "\n",
    "        sdf_field[x,y,z] = geometry\n",
    "\n",
    "@ti.kernel\n",
    "def render():\n",
    "    for u, v in color_buffer:\n",
    "        aspect_ratio = res[0] / res[1]\n",
    "        pos = camera_pos\n",
    "        d = ti.Vector([\n",
    "            (2 * fov * (u + ti.random()) / res[1] - fov * aspect_ratio - 1e-5),\n",
    "            2 * fov * (v + ti.random()) / res[1] - fov - 1e-5, -1.0\n",
    "        ])\n",
    "        d = d.normalized()\n",
    "\n",
    "        throughput = ti.Vector([1.0, 1.0, 1.0])\n",
    "\n",
    "        depth = 0\n",
    "        hit_light = 0.00\n",
    "\n",
    "        while depth < max_ray_depth:\n",
    "            closest, normal, c = next_hit(pos, d)\n",
    "            depth += 1\n",
    "            dist_to_light = intersect_light(pos, d)\n",
    "            if dist_to_light < closest:\n",
    "                hit_light = 1\n",
    "                depth = max_ray_depth\n",
    "            else:\n",
    "                hit_pos = pos + closest * d\n",
    "                if normal.norm_sqr() != 0:\n",
    "                    d = out_dir(normal)\n",
    "                    pos = hit_pos + 1e-4 * d\n",
    "                    throughput *= c\n",
    "                else:\n",
    "                    depth = max_ray_depth\n",
    "        color_buffer[u, v] += throughput * hit_light\n",
    "        \n",
    "import PIL.Image, PIL.ImageFont, PIL.ImageDraw\n",
    "import numpy as np\n",
    "import imageio\n",
    "import tqdm\n",
    "\n",
    "\n",
    "\n",
    "frames = []\n",
    "fill_sdf()\n",
    "for frame in tqdm.trange(60*5):\n",
    "  render()\n",
    "  img = color_buffer.to_numpy() * (1 / ( 0+ 1))\n",
    "  img = img / img.mean() * 0.24\n",
    "  img = np.sqrt(img)\n",
    "\n",
    "  frames.append(img)\n",
    "\n",
    "imageio.mimwrite('mpm88.mp4', frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from lib.libmise import mise\n",
    "\n",
    "scale = 1.1  # Scale of the padded bbox regarding the tight one.\n",
    "\n",
    "verts = smpl_verts.squeeze(0).data.cpu().numpy()\n",
    "gt_bbox = np.stack([verts.min(axis=0), verts.max(axis=0)], axis=0)\n",
    "gt_center = (gt_bbox[0] + gt_bbox[1]) * 0.5\n",
    "gt_scale = (gt_bbox[1] - gt_bbox[0]).max()\n",
    "\n",
    "mesh_extractor = mise.MISE(32, 4, 0)\n",
    "points = mesh_extractor.query()\n",
    "\n",
    "# query occupancy grid\n",
    "import time\n",
    "with torch.no_grad():\n",
    "    while points.shape[0] != 0:\n",
    "\n",
    "        orig_points = points\n",
    "        points = points.astype(np.float32)\n",
    "        points = (points / mesh_extractor.resolution - 0.5) * scale\n",
    "        points = points * gt_scale + gt_center\n",
    "        points = torch.tensor(points,device=smpl_verts.device,dtype=torch.float32)\n",
    "        print(points.shape)\n",
    "        start = time.time()\n",
    "        values = occ_func(points.unsqueeze(0))[:,0]\n",
    "        print('occ',time.time()-start)\n",
    "\n",
    "        start = time.time()\n",
    "        values = values.data.cpu().numpy().astype(np.float64)\n",
    "        print('cpu',time.time()-start)\n",
    "\n",
    "        start = time.time()\n",
    "        mesh_extractor.update(orig_points, values)\n",
    "        print('update',time.time()-start)\n",
    "\n",
    "        start = time.time()\n",
    "        points = mesh_extractor.query()\n",
    "        print('query',time.time()-start)\n",
    "\n",
    "value_grid = mesh_extractor.to_dense()\n",
    "print(value_grid.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " = 1.1  # Scale of the padded bbox regarding the tight one.\n",
    "\n",
    "verts = smpl_verts.squeeze(0).data.cpu().numpy()\n",
    "gt_bbox = np.stack([verts.min(axis=0), verts.max(axis=0)], axis=0)\n",
    "gt_center = (gt_bbox[0] + gt_bbox[1]) * 0.5\n",
    "gt_scale = (gt_bbox[1] - gt_bbox[0]).max()\n",
    "\n",
    "mesh_extractor = mise.MISE(32, 4, 0)\n",
    "points = mesh_extractor.query()\n",
    "\n",
    "# query occupancy grid\n",
    "import time\n",
    "with torch.no_grad():\n",
    "    while points.shape[0] != 0:\n",
    "\n",
    "        orig_points = points\n",
    "        points = points.astype(np.float32)\n",
    "        points = (points / mesh_extractor.resolution - 0.5) * scale\n",
    "        points = points * gt_scale + gt_center\n",
    "        points = torch.tensor(points,device=smpl_verts.device,dtype=torch.float32)\n",
    "        print(points.shape)\n",
    "        start = time.time()\n",
    "        values = occ_func(points.unsqueeze(0))[:,0]\n",
    "        print('occ',time.time()-start)\n",
    "\n",
    "        start = time.time()\n",
    "        values = values.data.cpu().numpy().astype(np.float64)\n",
    "        print('cpu',time.time()-start)\n",
    "\n",
    "        start = time.time()\n",
    "        mesh_extractor.update(orig_points, values)\n",
    "        print('update',time.time()-start)\n",
    "\n",
    "        start = time.time()\n",
    "        points = mesh_extractor.query()\n",
    "        print('query',time.time()-start)\n",
    "\n",
    "value_grid = mesh_extractor.to_dense()\n",
    "print(value_grid.shape)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('snarf1.10')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3b6afba02ba371daf83ae4b5130d96bcbc9a074bbca6494b4e2f39594f20b3af"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
